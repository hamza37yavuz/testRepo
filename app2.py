import gradio as gr
from diffusers import DiffusionPipeline
import torch
from huggingface_hub import login
import sys

class FluxImageGenerator:
    def __init__(self, model_id="black-forest-labs/FLUX.1-dev", devices=None):
        """
        FLUX.1-dev modelini yÃ¼kler ve ayarlar.
        
        Args:
            model_id (str): Hugging Face model kimliÄŸi.
            devices (list): KullanÄ±lacak GPU'larÄ±n listesi (Ã¶r. ["cuda:0", "cuda:1"]).
        """
        self.model_id = model_id
        self.devices = devices or ["cuda:0"]  # VarsayÄ±lan olarak tek GPU
        self.pipe = None  # Model baÅŸlangÄ±Ã§ta yÃ¼klenmemiÅŸ olacak

    def _load_model(self, token):
        """
        Modeli yÃ¼kler ve belirtilen GPU'lara daÄŸÄ±tÄ±r.
        
        Args:
            token (str): Hugging Face token'Ä±.
        """
        try:
            print(f"[DEBUG] Model yÃ¼kleniyor: {self.model_id}")
            self.pipe = DiffusionPipeline.from_pretrained(
                self.model_id,
                torch_dtype=torch.float16,
                use_auth_token=token  # Token'Ä± kullanarak modeli yÃ¼kle
            )
            
            # Ã‡oklu GPU kullanÄ±mÄ± (DataParallel)
            if len(self.devices) > 1:
                print(f"[DEBUG] {len(self.devices)} GPU kullanÄ±lÄ±yor: {', '.join(self.devices)}")
                self.pipe.enable_model_cpu_offload()  # Bellek optimizasyonu iÃ§in
            else:
                print(f"[DEBUG] Tek GPU kullanÄ±lÄ±yor: {self.devices[0]}")
                self.pipe = self.pipe.to(self.devices[0])

            print("[DEBUG] Model baÅŸarÄ±yla yÃ¼klendi!")
        except Exception as e:
            print(f"[ERROR] Model yÃ¼kleme baÅŸarÄ±sÄ±z oldu: {e}")
            raise RuntimeError(f"Model yÃ¼klenemedi: {e}")

    def generate_image(self, prompt):
        """
        Metin girdisine dayalÄ± olarak gÃ¶rsel oluÅŸturur.
        
        Args:
            prompt (str): Ä°stenen gÃ¶rseli tanÄ±mlayan metin.
        
        Returns:
            PIL.Image: OluÅŸturulan gÃ¶rsel.
        """
        negative_prompt = "ÅŸiddet, korku, Ã§Ä±plaklÄ±k"  # Sabit negatif prompt
        if self.pipe is None:
            raise gr.Error("[ERROR] Model yÃ¼klenmeden gÃ¶rsel oluÅŸturulamaz!")

        try:
            print(f"[DEBUG] GÃ¶rsel oluÅŸturuluyor: {prompt}")
            with torch.autocast(self.devices[0]):
                image = self.pipe(prompt, negative_prompt=negative_prompt, height=512, width=512).images[0]
            print("[DEBUG] GÃ¶rsel baÅŸarÄ±yla oluÅŸturuldu!")
            return image
        except Exception as e:
            print(f"[ERROR] GÃ¶rsel oluÅŸturulurken hata oluÅŸtu: {e}")
            raise RuntimeError(f"GÃ¶rsel oluÅŸturulamadÄ±: {e}")

def create_gradio_interface(generator):
    """
    Gradio arayÃ¼zÃ¼nÃ¼ oluÅŸturur.
    
    Returns:
        gr.Blocks: Gradio arayÃ¼zÃ¼.
    """

    def generate_image_wrapper(prompt):
        # Prompt'un 300 karakteri aÅŸmasÄ±nÄ± engelle
        if len(prompt) > 300:
            raise gr.Error("Prompt 300 karakteri geÃ§emez! LÃ¼tfen daha kÄ±sa bir metin girin.")
        return generator.generate_image(prompt)

    # Renkli ve Ã§ocuk dostu tema
    custom_theme = gr.themes.Default(
        primary_hue="teal",  # Ana renk
        secondary_hue="pink",  # Ä°kincil renk
        neutral_hue="gray",  # NÃ¶tr renk
        font=gr.themes.GoogleFont("Comic Neue"),  # EÄŸlenceli bir yazÄ± tipi
    )

    try:
        with gr.Blocks(theme=custom_theme) as demo:
            gr.Markdown("# ğŸ¨ FLUX.1-dev ile EÄŸlenceli GÃ¶rsel OluÅŸturma ğŸ¨")
            gr.Markdown("### Ã‡ocuklar iÃ§in renkli ve eÄŸlenceli gÃ¶rseller oluÅŸturun!")
            
            # GÃ¶rsel oluÅŸturma alanÄ±
            with gr.Row():
                with gr.Column():
                    prompt = gr.Textbox(
                        label="Prompt (Ä°stenen GÃ¶rsel)",
                        placeholder="Ã–rneÄŸin: Mutlu bir Ã§ocuk, renkli balonlarla",
                        max_lines=3,  # Metin kutusunun boyutunu sÄ±nÄ±rla
                        max_length=300,  # Maksimum 300 karakter
                        info="LÃ¼tfen 300 karakteri geÃ§meyen bir metin girin.",  # Bilgilendirme mesajÄ±
                    )
                    generate_button = gr.Button("GÃ¶rsel OluÅŸtur", variant="primary")
                with gr.Column():
                    output_image = gr.Image(label="OluÅŸturulan GÃ¶rsel", interactive=False)

            # Buton iÅŸlevleri
            generate_button.click(
                generate_image_wrapper,
                inputs=[prompt],
                outputs=output_image,
            )

            gr.Markdown("### Ã–rnek Promptlar:")
            gr.Examples(
                examples=[
                    ["Mutlu bir Ã§ocuk, yeÅŸil bir ormanda, gÃ¼neÅŸ Ä±ÅŸÄ±ÄŸÄ± altÄ±nda, renkli kelebeklerle Ã§evrili"],
                    ["Renkli balonlarla dolu bir parti, mutlu Ã§ocuklar, pastel renkler"],
                    ["Bir uzay gemisi, yÄ±ldÄ±zlar, gezegenler, renkli Ä±ÅŸÄ±klar"],
                ],
                inputs=[prompt],
                label="Ã–rnekler"
            )
        return demo
    except Exception as e:
        print(f"[ERROR] Gradio arayÃ¼zÃ¼ oluÅŸturulamadÄ±: {e}")
        raise RuntimeError(f"Gradio arayÃ¼zÃ¼ baÅŸlatÄ±lamadÄ±: {e}")

def main():
    # Komut satÄ±rÄ±ndan token alÄ±n
    if len(sys.argv) != 2:
        print("KullanÄ±m: python app2.py <HuggingFace_Token>")
        sys.exit(1)

    HUGGINGFACE_TOKEN = sys.argv[1]

    try:
        # Hugging Face hesabÄ±na giriÅŸ yap
        print("[DEBUG] Hugging Face hesabÄ±na giriÅŸ yapÄ±lÄ±yor...")
        login(token=HUGGINGFACE_TOKEN)
        print("[DEBUG] Hugging Face giriÅŸ baÅŸarÄ±lÄ±!")

        # Modeli yÃ¼kleyin (birden fazla GPU kullanÄ±mÄ± iÃ§in ayar)
        devices = [f"cuda:{i}" for i in range(torch.cuda.device_count())]
        if not devices:
            raise RuntimeError("KullanÄ±labilir GPU bulunamadÄ±.")
        generator = FluxImageGenerator(devices=devices)
        generator._load_model(HUGGINGFACE_TOKEN)

        # Gradio arayÃ¼zÃ¼nÃ¼ oluÅŸtur ve baÅŸlat
        demo = create_gradio_interface(generator)
        print("[DEBUG] Gradio arayÃ¼zÃ¼ baÅŸlatÄ±lÄ±yor...")
        demo.launch(server_name="0.0.0.0", server_port=7860)
    except Exception as e:
        print(f"[ERROR] Program baÅŸlatÄ±lamadÄ±: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
