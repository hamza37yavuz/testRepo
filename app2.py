import gradio as gr
from diffusers import DiffusionPipeline
import torch

class FluxImageGenerator:
    def __init__(self, model_id="black-forest-labs/FLUX.1-dev", device="cuda"):
        """
        FLUX.1-dev modelini yÃ¼kler ve ayarlar.
        
        Args:
            model_id (str): Hugging Face model kimliÄŸi.
            device (str): KullanÄ±lacak cihaz ("cuda" veya "cpu").
        """
        self.model_id = model_id
        self.device = device
        self.pipe = None  # Model baÅŸlangÄ±Ã§ta yÃ¼klenmemiÅŸ olacak

    def _load_model(self, token):
        """
        Modeli yÃ¼kler ve belirtilen cihaza taÅŸÄ±r.
        
        Args:
            token (str): Hugging Face token'Ä±.
        """
        print(f"Model yÃ¼kleniyor: {self.model_id}")
        self.pipe = DiffusionPipeline.from_pretrained(
            self.model_id,
            torch_dtype=torch.float16,
            use_auth_token=token  # Token'Ä± kullanarak modeli yÃ¼kle
        )
        self.pipe = self.pipe.to(self.device)
        print("Model baÅŸarÄ±yla yÃ¼klendi!")

    def generate_image(self, prompt, negative_prompt=""):
        """
        Metin girdisine dayalÄ± olarak gÃ¶rsel oluÅŸturur.
        
        Args:
            prompt (str): Ä°stenen gÃ¶rseli tanÄ±mlayan metin.
            negative_prompt (str): Ä°stenmeyen Ã¶ÄŸeleri tanÄ±mlayan metin.
        
        Returns:
            PIL.Image: OluÅŸturulan gÃ¶rsel.
        """
        if self.pipe is None:
            raise gr.Error("LÃ¼tfen Ã¶nce Hugging Face token'Ä±nÄ±zÄ± girin ve modeli yÃ¼kleyin!")
        
        print(f"GÃ¶rsel oluÅŸturuluyor: {prompt}")
        with torch.autocast(self.device):
            image = self.pipe(prompt, negative_prompt=negative_prompt).images[0]
        print("GÃ¶rsel baÅŸarÄ±yla oluÅŸturuldu!")
        return image

def create_gradio_interface():
    """
    Gradio arayÃ¼zÃ¼nÃ¼ oluÅŸturur.
    
    Returns:
        gr.Blocks: Gradio arayÃ¼zÃ¼.
    """
    generator = FluxImageGenerator(device="cuda")  # GPU kullanÄ±yorsanÄ±z, "cpu" yerine "cuda" yazÄ±n

    def load_model_wrapper(token):
        """
        Modeli yÃ¼klemek iÃ§in wrapper fonksiyonu.
        """
        try:
            generator._load_model(token)
            return "Model baÅŸarÄ±yla yÃ¼klendi!"
        except Exception as e:
            return f"Hata: {str(e)}"

    def generate_image_wrapper(prompt, negative_prompt):
        # Prompt'un 300 karakteri aÅŸmasÄ±nÄ± engelle
        if len(prompt) > 300:
            raise gr.Error("Prompt 300 karakteri geÃ§emez! LÃ¼tfen daha kÄ±sa bir metin girin.")
        return generator.generate_image(prompt, negative_prompt)

    # Renkli ve Ã§ocuk dostu tema
    custom_theme = gr.themes.Default(
        primary_hue="teal",  # Ana renk
        secondary_hue="pink",  # Ä°kincil renk
        neutral_hue="gray",  # NÃ¶tr renk
        font=gr.themes.GoogleFont("Comic Neue"),  # EÄŸlenceli bir yazÄ± tipi
    )

    with gr.Blocks(theme=custom_theme) as demo:
        gr.Markdown("# ğŸ¨ FLUX.1-dev ile EÄŸlenceli GÃ¶rsel OluÅŸturma ğŸ¨")
        gr.Markdown("### Ã‡ocuklar iÃ§in renkli ve eÄŸlenceli gÃ¶rseller oluÅŸturun!")
        
        # Token giriÅŸi iÃ§in bir alan ekleyin
        with gr.Row():
            token_input = gr.Textbox(
                label="Hugging Face Token",
                placeholder="hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
                type="password",  # Token'Ä± gizli tut
                info="Hugging Face hesabÄ±nÄ±zÄ±n token'Ä±nÄ± girin.",
            )
            load_model_button = gr.Button("Modeli YÃ¼kle", variant="secondary")
        
        load_model_output = gr.Textbox(label="Model YÃ¼kleme Durumu", interactive=False)
        
        # Model yÃ¼klendikten sonra gÃ¶rsel oluÅŸturma alanÄ±
        with gr.Row():
            with gr.Column():
                prompt = gr.Textbox(
                    label="Prompt (Ä°stenen GÃ¶rsel)",
                    placeholder="Ã–rneÄŸin: Mutlu bir Ã§ocuk, renkli balonlarla",
                    max_lines=3,  # Metin kutusunun boyutunu sÄ±nÄ±rla
                    max_length=300,  # Maksimum 300 karakter
                    info="LÃ¼tfen 300 karakteri geÃ§meyen bir metin girin.",  # Bilgilendirme mesajÄ±
                )
                negative_prompt = gr.Textbox(
                    label="Negatif Prompt (Ä°stenmeyen Ã–ÄŸeler)",
                    placeholder="Ã–rneÄŸin: ÅŸiddet, korku, Ã§Ä±plaklÄ±k",
                    max_lines=2,  # Metin kutusunun boyutunu sÄ±nÄ±rla
                )
                generate_button = gr.Button("GÃ¶rsel OluÅŸtur", variant="primary")
            with gr.Column():
                output_image = gr.Image(label="OluÅŸturulan GÃ¶rsel", interactive=False)

        # Buton iÅŸlevleri
        load_model_button.click(
            load_model_wrapper,
            inputs=token_input,
            outputs=load_model_output,
        )
        generate_button.click(
            generate_image_wrapper,
            inputs=[prompt, negative_prompt],
            outputs=output_image,
        )

        gr.Markdown("### Ã–rnek Promptlar:")
        gr.Examples(
            examples=[
                ["Mutlu bir Ã§ocuk, yeÅŸil bir ormanda, gÃ¼neÅŸ Ä±ÅŸÄ±ÄŸÄ± altÄ±nda, renkli kelebeklerle Ã§evrili", "ÅŸiddet, korku"],
                ["Renkli balonlarla dolu bir parti, mutlu Ã§ocuklar, pastel renkler", "karanlÄ±k, Ã¼zÃ¼ntÃ¼"],
                ["Bir uzay gemisi, yÄ±ldÄ±zlar, gezegenler, renkli Ä±ÅŸÄ±klar", "ÅŸiddet, korku"],
            ],
            inputs=[prompt, negative_prompt],
            label="Ã–rnekler"
        )

    return demo

def main():
    # Gradio arayÃ¼zÃ¼nÃ¼ oluÅŸtur
    demo = create_gradio_interface()

    # ArayÃ¼zÃ¼ dÄ±ÅŸarÄ±dan eriÅŸilebilir ÅŸekilde baÅŸlat
    demo.launch(server_name="0.0.0.0", server_port=7860)

if __name__ == "__main__":
    main()
