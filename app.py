import gradio as gr
from google.cloud import translate_v2 as translate
from diffusers import StableDiffusionPipeline
import torch

# Google Translate API istemcisi
translate_client = translate.Client()

# Stable Diffusion Pipeline'i yÃ¼kleme
def load_pipeline():
    try:
        print("Stable Diffusion Pipeline yÃ¼kleniyor...")
        pipe = StableDiffusionPipeline.from_pretrained(
            "CompVis/stable-diffusion-v1-4",
            cache_dir="./cache",
            resume_download=True,
            timeout=120
        )
        device = "cuda" if torch.cuda.is_available() else "cpu"
        pipe = pipe.to(device)
        print(f"Model {device.upper()} Ã¼zerinde Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor.")
        return pipe
    except Exception as e:
        print(f"Model yÃ¼kleme sÄ±rasÄ±nda hata oluÅŸtu: {e}")
        return None

pipe = load_pipeline()

# Ã‡eviri fonksiyonu (Google Translate API)
def translate_to_english_google_api(prompt):
    try:
        result = translate_client.translate(prompt, source_language="tr", target_language="en")
        return result["translatedText"]
    except Exception as e:
        print(f"Ã‡eviri sÄ±rasÄ±nda hata oluÅŸtu: {e}")
        return prompt

# GÃ¶rsel Ã¼retim fonksiyonu
negative_prompt = (
    "violence, explicit content, gore, inappropriate for children, "
    "blood, weapon, nudity"
)

def generate_image(prompt, width, height, translate_prompt):
    if pipe is None:
        return "Model yÃ¼klenemedi, lÃ¼tfen tekrar deneyin.", None

    if len(prompt) > 200:
        return "Prompt Ã§ok uzun! LÃ¼tfen 200 karakterden kÄ±sa bir ÅŸey girin.", None
    if width > 400 or height > 400:
        return "Boyutlar sÄ±nÄ±rÄ± aÅŸÄ±yor! Maksimum boyut 400x400 olmalÄ±dÄ±r.", None

    try:
        # Prompt Ã§evirme seÃ§eneÄŸi
        if translate_prompt:
            prompt = translate_to_english_google_api(prompt)

        # GÃ¶rseli Ã¼ret
        image = pipe(prompt, width=width, height=height, negative_prompt=negative_prompt).images[0]
        return None, image
    except Exception as e:
        print(f"GÃ¶rsel Ã¼retim sÄ±rasÄ±nda hata oluÅŸtu: {e}")
        return "GÃ¶rsel Ã¼retim sÄ±rasÄ±nda bir hata oluÅŸtu.", None

# GPU veya CPU durumunu kontrol eden fonksiyon
def check_device():
    if torch.cuda.is_available():
        return "GPU kullanÄ±lÄ±yor."
    else:
        return "GPU kullanÄ±lmÄ±yor, CPU Ã¼zerinde Ã§alÄ±ÅŸÄ±yor."

# Gradio arayÃ¼zÃ¼
with gr.Blocks(css="body {background: linear-gradient(135deg, #ff7eb3, #ff758c, #ffd5cd);}") as demo:
    gr.Markdown("### ğŸ¨ Stable Diffusion: Yapay Zeka EÄŸitim GÃ¶rsel Ãœretimi")

    with gr.Row():
        prompt = gr.Textbox(label="Prompt (TÃ¼rkÃ§e)", placeholder="Bir ÅŸey yazÄ±n (max 200 karakter)")
        width = gr.Slider(label="GeniÅŸlik", minimum=100, maximum=400, step=50, value=400)
        height = gr.Slider(label="YÃ¼kseklik", minimum=100, maximum=400, step=50, value=400)

    with gr.Row():
        translate_prompt = gr.Checkbox(label="Ä°ngilizce'ye Ã§evir (Google Translate API)", value=True)
        device_status = gr.Textbox(label="Cihaz Durumu", value=check_device(), interactive=False)

    output_text = gr.Textbox(label="Hata MesajÄ±")
    output_image = gr.Image(label="Ãœretilen GÃ¶rsel")

    generate_button = gr.Button("GÃ¶rsel Ãœret")
    generate_button.click(
        fn=generate_image,
        inputs=[prompt, width, height, translate_prompt],
        outputs=[output_text, output_image]
    )

demo.launch(server_name="0.0.0.0", server_port=7860)
